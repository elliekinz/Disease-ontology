{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import sys\n",
    "sys.path.append('./../')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec, doc2vec\n",
    "model_trigram = word2vec.Word2Vec.load('models/trigram_100features_10minwords_5context')\n",
    "model_doc2vec = doc2vec.Doc2Vec.load('models/doc2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from time import sleep\n",
    "\n",
    "from wiki_pubmed_fuzzy.ontology import get_ontology\n",
    "import fuzzywuzzy.process as fuzzy_process\n",
    "from fuzzywuzzy import fuzz\n",
    "from wiki_pubmed_fuzzy import wiki\n",
    "from wiki_pubmed_fuzzy import pubmed\n",
    "\n",
    "from bot.lookup import search_doid\n",
    "import NLP\n",
    "#from xxx import xxx \n",
    "\n",
    "from bot import lookup\n",
    "\n",
    "query_results = None\n",
    "def fn_get_q(query, names):\n",
    "    try:\n",
    "        global query_results\n",
    "        query_results = fuzzy_process.extractOne(query, names, scorer=fuzz.WRatio)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "wiki_results = None\n",
    "def fn_get_wiki(query, names):\n",
    "    try:\n",
    "        global wiki_results\n",
    "        header = wiki.get_top_headers(query, 1)[0]\n",
    "        wiki_results = fuzzy_process.extractOne(header, names, scorer=fuzz.ratio)\n",
    "        #sleep(0.1)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "pubmed_results = None\n",
    "def fn_get_pubmed(query, names):\n",
    "    global pubmed_results\n",
    "    string = pubmed.get(query, topK=1)\n",
    "\n",
    "    if string is not None:\n",
    "        string = string[0]\n",
    "        pubmed_results = fuzzy_process.extractOne(string, names, scorer=fuzz.partial_ratio)\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "'''main'''\n",
    "## from bot\n",
    "query = 'degenerative disease'\n",
    "\n",
    "def find_answer(query, model_trigram, model_doc2vec):\n",
    "    query = query.lower()\n",
    "    \n",
    "    # load ontology\n",
    "    ontology = get_ontology('data/doid.obo')\n",
    "    name2doid = {term.name: term.id for term in ontology.get_terms()}\n",
    "    names = name2doid.keys()\n",
    "    doid2name = {term.id: term.name for term in ontology.get_terms()}\n",
    "    \n",
    "    ## exact match\n",
    "    if query in name2doid.keys():\n",
    "        doid = name2doid[query]\n",
    "        confidence = 100\n",
    "    else:\n",
    "        # no exact match\n",
    "        th_get_q = Thread(target = fn_get_q, args = (query,names,))\n",
    "        th_get_wiki = Thread(target = fn_get_wiki, args = (query,names,))\n",
    "        th_get_pubmed = Thread(target = fn_get_pubmed, args = (query,names,))\n",
    "\n",
    "        th_get_q.start()\n",
    "        th_get_wiki.start()\n",
    "        th_get_pubmed.start()\n",
    "\n",
    "        ## search engine query --> vertices, p=100(NLP??); synonyms\n",
    "        doids = set()\n",
    "        doid_exact_results = search_doid(query, False, doids)\n",
    "        print doids\n",
    "\n",
    "        ## synonyms NLP\n",
    "        \n",
    "        #synonyms = NLP(query)\n",
    "\n",
    "        ## new thread for NLP\n",
    "\n",
    "        ## tree search on vertices (returned + synonyms)\n",
    "        \n",
    "        ## sleep ?\n",
    "\n",
    "        th_get_q.join()\n",
    "        print query_results\n",
    "\n",
    "        th_get_wiki.join()\n",
    "        print wiki_results\n",
    "\n",
    "        th_get_pubmed.join()\n",
    "        print pubmed_results\n",
    "\n",
    "        \n",
    "        #prob_vec = NLP2(query, synonyms)\n",
    "        \n",
    "        ## final answer\n",
    "        ## draw graph\n",
    "\n",
    "        doid = None\n",
    "    \n",
    "    graph = None\n",
    "    string = (\"Query: {:}\\n\".format(query) + \n",
    "              \"{:}\\n\".format(doid) + \n",
    "              \"Name: {:}\\n\".format(doid2name[doid]) + \n",
    "              \"Confidence: {:}\\%\\n\".format(confidence))\n",
    "    return string, graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'DOID:8398', u'DOID:11829', u'DOID:90', u'DOID:0060844', u'HP:0005237', u'DOID:9799', u'HP:0001379', u'DOID:1289', u'DOID:10120'])\n",
      "('degenerative disc disease', 95)\n",
      "('eye degenerative disease', 91)\n",
      "('disease', 100)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-53857e14ee66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mfind_answer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-2485d8c88b6b>\u001b[0m in \u001b[0;36mfind_answer\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m    106\u001b[0m     string = (\"Query: {:}\\n\".format(query) + \n\u001b[0;32m    107\u001b[0m               \u001b[1;34m\"{:}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m               \u001b[1;34m\"Name: {:}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoid2name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m               \"Confidence: {:}\\%\\n\".format(confidence))\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "print find_answer(query)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ontology = get_ontology('../data/doid.obo')\n",
    "name2doid = {term.name: term.id for term in ontology.get_terms()}\n",
    "doid2name = {term.id: term.name for term in ontology.get_terms()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wiki links from obo descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example:'http://en.wikipedia.org/wiki/Abetalipoproteinemia'\n"
     ]
    }
   ],
   "source": [
    "lst = wiki.get_links_from_ontology(ontology)\n",
    "print r'example:{:}'.format(repr(lst[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urllib2 to read page in html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\\n<head>\\n<meta charset=\"UTF-8\"/>\\n<title>Ameloblastoma - Wikipedia</title>\\n<script>document.documentElement.className = document.documentElement.className.replace( /(^|\\\\s)client-nojs(\\\\s|$)/, \"$1client-js$2\" );</script>\\n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Ameloblastoma\",\"wgTitle\":\"Ameloblastoma\",\"wgCurRevisionId\":766170591,\"wgRevisionId\":766170591,\"wgArticleId\":2020081,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"All articles with dead external links\",\"Articles with dead external links from February 2017\",\"Articles with contributors link\",\"Articles needing additional references from March 2009\",\"All articles needing additional references\",\"Commons category with local link same as on Wikidata\",\"Odontogenic tumors\"],\"wgBreakFrames\":fals'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = wiki.get_html(lst[101])\n",
    "page[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('arrhythmogenic right ventricular cardiomyopathy', 67)\n"
     ]
    }
   ],
   "source": [
    "string = \"ventricular arrhythmia\"\n",
    "names = np.sort(name2doid.keys())\n",
    "print fuzzy_process.extractOne(string, names, scorer=fuzz.token_set_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hairy cell leukemia', 100)\n"
     ]
    }
   ],
   "source": [
    "string = \"Complete remission of hairy cell leukemia variant (HCL-v) complicated by red cell aplasia post treatment with rituximab.\"\n",
    "print fuzzy_process.extractOne(string, names, scorer=fuzz.partial_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia search engine: headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Cardiac arrhythmia',\n",
       " u'Re-entry ventricular arrhythmia',\n",
       " u'Ventricular fibrillation']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"ventricular arrhythmia\"\n",
    "\n",
    "top = wiki.get_top_headers(query)\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cardiac arrest', 75)\n",
      "('arrhythmogenic right ventricular cardiomyopathy', 67)\n",
      "('atrial fibrillation', 79)\n"
     ]
    }
   ],
   "source": [
    "for header in top:\n",
    "    results = fuzzy_process.extractOne(header, names, scorer=fuzz.token_set_ratio)\n",
    "    print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'The term cell growth is used in the contexts of biological cell development and cell division (reproduction). When used in the context of cell division, it refers to growth of cell populations, where a cell, known as the \"mother cell\", grows and divides to produce two \"daughter cells\" (M phase). When used in the context of cell development, the term refers to increase in cytoplasmic and organelle volume (G1 phase), as well as increase in genetic material (G2 phase) following the replication during S phase.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = wikipedia.WikipediaPage(title='Cell_proliferation')\n",
    "page.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[name for name in names if len(re.split(' ', name)) > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pub-med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Complete remission of hairy cell leukemia variant (HCL-v) complicated by red cell aplasia post treatment with rituximab.\n",
      "('hairy cell leukemia', 100)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'hcl-v'\n",
    "titles = pubmed.get(query)\n",
    "titles_len = [len(title) for title in titles] \n",
    "for i, string in enumerate(titles):\n",
    "    print(\"%d) %s\" % (i+1, string))\n",
    "    print fuzzy_process.extractOne(string, names, scorer=fuzz.partial_ratio)\n",
    "    print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def find_synonym(s_ref, s):\n",
    "    last = s_ref.find('(' + s + ')')\n",
    "    if last == -1:\n",
    "        return None\n",
    "    \n",
    "    n_upper = len(''.join([c for c in s if c.isupper()]))\n",
    "    first = [(i,c) for i, c in enumerate(s_ref[:last]) if c.isupper()][-n_upper][0]\n",
    "    return s_ref[first:last-1]\n",
    "\n",
    "print find_synonym('Wolff-Parkinson-White syndrome (WPW) and athletes: Darwin at play?',\n",
    "             'WPW')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wolff parkinson white \n",
      "hairy cell leukemia variant \n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "print utils.find_synonym('Wolff-Parkinson-White syndrome (WPW) and athletes: Darwin at play?', 'WPW')\n",
    "print utils.find_synonym('Complete remission of hairy cell leukemia variant (HCL-v)...', 'hcl-v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assymetric distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "s_ref = 'artery disease'\n",
    "s = 'nonartery'\n",
    "print utils.assym_dist(s, s_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean term name length: 27.5502935797\n",
      "Mean article title length: 120.0\n"
     ]
    }
   ],
   "source": [
    "print 'Mean term name length:', np.mean([len(term.name) for term in ontology.get_terms()])\n",
    "print 'Mean article title length:', np.mean(titles_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(+)ssrna',\n",
       " '(1p)',\n",
       " '(atp',\n",
       " '(perianal)',\n",
       " ')ssrna',\n",
       " '1.4mb',\n",
       " '10q23',\n",
       " '13q14',\n",
       " '14q11',\n",
       " '15q11.2']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [re.split(' |-', term.name) for term in ontology.get_terms()]\n",
    "words = np.unique([l for sublist in words for l in sublist if len(l) > 0])\n",
    "words = [w for w in words if len(w) >= 4]\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
